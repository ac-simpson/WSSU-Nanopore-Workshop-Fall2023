{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e57dd22",
   "metadata": {},
   "source": [
    "# Organizing and visualizing Nanopore data\n",
    "\n",
    "1. Navigating the results of a Nanopore run\n",
    "2. Combining fastq files from a run\n",
    "3. Visualizing the run using Nanoplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bede79",
   "metadata": {},
   "source": [
    "## 1. Navigating the results of a Nanopore run\n",
    "\n",
    "The software on an Mk1C, or MinKNOW on a computer when running an Mk1B, allows you to look at how a Nanopore sequencing run is going in real time. Once a Nanopore run is finished, a report is generated that you can inspect at your leisure, as well as the fast5 and resultant fastq files from the run. We will inspect each element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c877b9d1",
   "metadata": {},
   "source": [
    "As part of her summer work, Jessica was trying out sequencing on a Flongle flow cell using Zymo's mock microbial DNA as the DNA input. She used the 16S amplicon library prep kit to generate full-length 16S sequences. She used barcodes to differentiate between multiple samples; for each barcode she used a different concentration of DNA. The purpose of this was to test whether the Flongle flow cell could accurately sequence small amounts of DNA.\n",
    "\n",
    "In this case, the Flongle flow cells sat in the Texas heat for multiple days before they made it to the lab. as we've discussed, Nanopore flow cells do not appreciate that! Jessica decided to use one of them to practice on and see if she could get good data. Did she? We'll be the judge of that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9139eb9e",
   "metadata": {},
   "source": [
    "Let's navigate to the folder Jessica_Zymo_DNA_16S_flongle_test and see what's in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c0fbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230814_1517_MN35209_NEW001_ada67482\n"
     ]
    }
   ],
   "source": [
    "cd data/Jessica_Zymo_DNA_16S_flongle_test\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2d050",
   "metadata": {},
   "source": [
    "There is only one folder, showing a date along with other information: \n",
    "\n",
    "\"[start_time]\\_[device_ID]\\_[flow_cell_id]\\_[short_protocol_run_id]\" - \n",
    "\n",
    "that's the result file. Let's navigate inside further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9962269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barcode_alignment_NEW001_ada67482_8572d6d5.tsv\n",
      "fast5_fail\n",
      "fast5_pass\n",
      "fast5_skip\n",
      "fastq_fail\n",
      "fastq_pass\n",
      "final_summary_NEW001_ada67482_8572d6d5.txt\n",
      "other_reports\n",
      "pore_activity_NEW001_ada67482_8572d6d5.csv\n",
      "report_NEW001_20230814_1522_ada67482.html\n",
      "report_NEW001_20230814_1522_ada67482.json\n",
      "report_NEW001_20230814_1522_ada67482.md\n",
      "sample_sheet_NEW001_20230814_1522_ada67482.csv\n",
      "sequencing_summary_NEW001_ada67482_8572d6d5.txt\n",
      "throughput_NEW001_ada67482_8572d6d5.csv\n"
     ]
    }
   ],
   "source": [
    "cd 20230814_1517_MN35209_NEW001_ada67482\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b1432",
   "metadata": {},
   "source": [
    "***What is in the result folder from a Nanopore run?***\n",
    "\n",
    "Record of the barcodes used in this experiment\n",
    "1. barcode_alignment_NEW001_ada67482_8572d6d5.tsv\n",
    "***\n",
    "Directories containing fast5 files - these are the files containing the raw signals from the pores. MinKNOW acquires these data in chunks from the device, decides where reads begin and end, and saves them to fast5 files (newer technology has switched to using pod5 format which is an upgraded file storage system, but that's too rich for our blood so far).\n",
    "***\n",
    "2. fast5_fail <-- quality below threshold set by software (default is Q score of 7)\n",
    "3. fast5_pass <-- quality above threshhold\n",
    "4. fast5_skip <-- real-time basecalling not fast enough to deal with these so MinKNOW puts them aside here\n",
    "***\n",
    "Directories containing fastq files - this is your raw sequencing data. Basecalling software (in this case, Guppy which is part of MinKNOW) determines how the 'squiggles' - i.e. the raw signals from the pores - translate into nucleotides. Fastq files contain both the nucleotide sequences and the quality score associated with each base, while fasta files contain only nucleotide sequences\n",
    "\n",
    "5. fastq_fail <-- bad quality reads\n",
    "6. fastq_pass <-- good quality reads (or at least above average quality threshold)\n",
    "***\n",
    "A variety of reports showing different metrics of how the sequencing run went.\n",
    "\n",
    "7. final_summary_NEW001_ada67482_8572d6d5.txt\n",
    "8. other_reports\n",
    "9. pore_activity_NEW001_ada67482_8572d6d5.csv\n",
    "10. report_NEW001_20230814_1522_ada67482.html\n",
    "11. report_NEW001_20230814_1522_ada67482.json\n",
    "12. report_NEW001_20230814_1522_ada67482.md\n",
    "13. sample_sheet_NEW001_20230814_1522_ada67482.csv\n",
    "14. sequencing_summary_NEW001_ada67482_8572d6d5.txt\n",
    "15. throughput_NEW001_ada67482_8572d6d5.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485327e",
   "metadata": {},
   "source": [
    "The fastq_pass folder is where the sequencing results that passed MinKNOW's original quality filter are located - let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73d1ef40-8cb2-4fa0-b809-95a8e6aefec5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barcode02\t\t\tbarcode07\n",
      "barcode04\t\t\tmy_happy_sequencing_data.fastq\n",
      "barcode05\t\t\tunclassified\n",
      "barcode06\n"
     ]
    }
   ],
   "source": [
    "ls fastq_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d40ce",
   "metadata": {},
   "source": [
    "As we can see, it's full of subdirectories with the names of the different barcodes. The software in MinKNOW automatically checks for the barcode tag on each sequence and puts it in its proper folder. If it can't figure out which barcode it is, or if it can't find a barcode (it's not a 100% perfect process), the sequence goes in the \"unclassfied\" folder. \n",
    "\n",
    "Now, let's examine what's inside one of these barcode folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2802cb16-9a12-4807-9b49-10508e19db75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd fastq_pass/barcode02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c9a9ec4-c36a-49e7-92e3-8fd667272768",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW001_pass_barcode02_ada67482_8572d6d5_0.fastq\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0aab34",
   "metadata": {},
   "source": [
    "Looks like there is only one file of sequencing results, meaning there wasn't a lot of data. As Nanopore sequencing continues, the MinKNOW program will write the sequencing results to a file once the amount of data it's collected has reached a certain threshold - then it will begin again, building a new file. See how this file ends in 0? If there had been more sequencing results, you would see files labeled with 1, 2, 3, etc., sometimes into the hundreds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d05a25b",
   "metadata": {},
   "source": [
    "Let's unzip the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44517d17-04f3-49af-9dcf-20bf7da61bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gunzip NEW001_pass_barcode02_ada67482_8572d6d5_0.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95f67985-ce20-472c-8aa0-7e7ad2ea67de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW001_pass_barcode02_ada67482_8572d6d5_0.fastq\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4fe3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now let's navigate to the barcode04 folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "694a686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../barcode04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e440853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW001_pass_barcode04_ada67482_8572d6d5_0.fastq\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7e2524",
   "metadata": {},
   "source": [
    "Hmm, only one sequencing file there too. Let's unzip it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "629cfdc6-f771-4572-98f5-8c5863d18ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gunzip NEW001_pass_barcode04_ada67482_8572d6d5_0.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a90cca",
   "metadata": {},
   "source": [
    "Now, let's try concatenating these two files with the different barcodes into a single fastq file, called \"my_happy_sequencing_data.fastq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b1689f0-0485-419f-a5b4-cee34c833e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat barcode02/NEW001_pass_barcode02_ada67482_8572d6d5_0.fastq barcode04/NEW001_pass_barcode04_ada67482_8572d6d5_0.fastq > my_happy_sequencing_data.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "904d10d2-e35a-477c-a9fb-3da2d596bf6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barcode02  barcode05  barcode07\t\t\t      unclassified\n",
      "barcode04  barcode06  my_happy_sequencing_data.fastq\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe785b",
   "metadata": {},
   "source": [
    "Why did we do that? For some of the programs you might wish to use on your Nanopore data, they will require all of the sequencing data for a sample to be in a single file. Using the cat command allows you to combine the contents of multiple files into one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa16243",
   "metadata": {},
   "source": [
    "#### Exploring the output files of the run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e7988",
   "metadata": {},
   "source": [
    "Now we will look at the output file from this sequencing run. In the menu on the left-hand side, navigate to Jessica's sequencing results folder and click on 'report_NEW001_20230814_1522_ada67482.html'. We will go through the results of this run together. (did this run go well?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8179659",
   "metadata": {},
   "source": [
    "## 2. Visualizing and examining Nanopore data with Nanoplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09c7044",
   "metadata": {},
   "source": [
    "Let's go back to the main data folder. Now we're going to use a program called Nanoplot (already installed for you) to explore and visualize some data from a Nanopore run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "018f8f67-361e-4e73-a445-53d7b14947d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: cd: /Users/asimpson/data: No such file or directory\n",
      "NEW001_pass_barcode04_ada67482_8572d6d5_0.fastq\n"
     ]
    }
   ],
   "source": [
    "cd ~/data\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3460b5",
   "metadata": {},
   "source": [
    "#### Using flags\n",
    "\n",
    "Many/most programs that you run on the command line will use 'flags' - input options that start with a dash and then a letter or a word to indicate what kind of information that flag is looking for. The short commands you learned earlier today in the intro to bash all have flags you can use, if you want to make your commands more specific or useful. \n",
    "\n",
    "For built-in commands in Unix like ls, cd, mv, etc. you can use the word 'man' (short for manual) followed by the command to see all of the possible flags/options. Try looking at the manual for 'ls' below. To refresh your memory, ls lists the contents of a file. But there are lots of ways to list the contents! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d122d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "man ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10625443",
   "metadata": {},
   "source": [
    "That's a lot, right? Most of that you likely won't ever use. \n",
    "\n",
    "However, you'll need to know how to use flags to be able to input data into a program in the command prompt.\n",
    "\n",
    "Most of the programs you'll be using for bioinformatics purposes allow you to look at the input options using the flag '-h' or '--help' - the help menu, basically. Let's explore the input options for the program \"fastANI\", which is already pre-installed, by using the -h flag. (fastANI calculates average nucleotide identity between two genomes - we won't be using it today but I'm using it as an example of a nice, simple, well-written help menu!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc70d20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "fastANI is a fast alignment-free implementation for computing whole-genome Average Nucleotide Identity (ANI) between genomes\n",
      "-----------------\n",
      "Example usage:\n",
      "$ fastANI -q genome1.fa -r genome2.fa -o output.txt\n",
      "$ fastANI -q genome1.fa --rl genome_list.txt -o output.txt\n",
      "\n",
      "SYNOPSIS\n",
      "--------\n",
      "fastANI [-h] [-r <value>] [--rl <value>] [-q <value>] [--ql <value>] [-k\n",
      "        <value>] [-t <value>] [--fragLen <value>] [--minFraction <value>]\n",
      "        [--visualize] [--matrix] [-o <value>] [-v]\n",
      "\n",
      "OPTIONS\n",
      "--------\n",
      "-h, --help\n",
      "     print this help page\n",
      "\n",
      "-r, --ref <value>\n",
      "     reference genome (fasta/fastq)[.gz]\n",
      "\n",
      "--rl, --refList <value>\n",
      "     a file containing list of reference genome files, one genome per line\n",
      "\n",
      "-q, --query <value>\n",
      "     query genome (fasta/fastq)[.gz]\n",
      "\n",
      "--ql, --queryList <value>\n",
      "     a file containing list of query genome files, one genome per line\n",
      "\n",
      "-k, --kmer <value>\n",
      "     kmer size <= 16 [default : 16]\n",
      "\n",
      "-t, --threads <value>\n",
      "     thread count for parallel execution [default : 1]\n",
      "\n",
      "--fragLen <value>\n",
      "     fragment length [default : 3,000]\n",
      "\n",
      "--minFraction <value>\n",
      "     minimum fraction of genome that must be shared for trusting ANI. If\n",
      "     reference and query genome size differ, smaller one among the two is\n",
      "     considered. [default : 0.2]\n",
      "\n",
      "--visualize\n",
      "     output mappings for visualization, can be enabled for single genome to\n",
      "     single genome comparison only [disabled by default]\n",
      "\n",
      "--matrix\n",
      "     also output ANI values as lower triangular matrix (format inspired from\n",
      "     phylip). If enabled, you should expect an output file with .matrix\n",
      "     extension [disabled by default]\n",
      "\n",
      "-o, --output <value>\n",
      "     output file name\n",
      "\n",
      "-v, --version\n",
      "     show version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fastANI -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5318db",
   "metadata": {},
   "source": [
    "Of interest: Based on the example, it looks like we would an input genome to be the query (-q) and an input genome to be the reference (-r), and the name of an output file (-o). That seems to be all we need to run the program - as the example in the help men shows.\n",
    "\n",
    "fastANI -q genome1.fa -r genome2.fa -o output.txt\n",
    "\n",
    "of note: the -t command. This specifies the number of threads/CPUs (i.e. parallel processes) the program can use. This is very important in bioinformatics because often, a process will take a very very long time unless you give it multiple threads. It used to be that personal computers didn't even have multiple threads to use, although that is changing now. However, right now we are logged onto a Linux server which does support multithreading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c162194",
   "metadata": {},
   "source": [
    "#### Nanoplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea13d55f",
   "metadata": {},
   "source": [
    "Now let's check out the options for Nanoplot, a program for filtering and visualizing Nanopore data. Let's look at the help menu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c315d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Nanoplot [-h] [-v] [-t THREADS] [--verbose] [--store] [--raw] [--huge]\n",
      "                [-o OUTDIR] [--no_static] [-p PREFIX] [--tsv_stats]\n",
      "                [--info_in_report] [--maxlength N] [--minlength N]\n",
      "                [--drop_outliers] [--downsample N] [--loglength]\n",
      "                [--percentqual] [--alength] [--minqual N] [--runtime_until N]\n",
      "                [--readtype {1D,2D,1D2}] [--barcoded] [--no_supplementary]\n",
      "                [-c COLOR] [-cm COLORMAP]\n",
      "                [-f [{png,jpg,jpeg,webp,svg,pdf,eps,json} ...]]\n",
      "                [--plots [{kde,hex,dot} ...]] [--legacy [{kde,dot,hex} ...]]\n",
      "                [--listcolors] [--listcolormaps] [--no-N50] [--N50]\n",
      "                [--title TITLE] [--font_scale FONT_SCALE] [--dpi DPI]\n",
      "                [--hide_stats]\n",
      "                (--fastq file [file ...] | --fasta file [file ...] | --fastq_rich file [file ...] | --fastq_minimal file [file ...] | --summary file [file ...] | --bam file [file ...] | --ubam file [file ...] | --cram file [file ...] | --pickle pickle | --feather file [file ...])\n",
      "\n",
      "CREATES VARIOUS PLOTS FOR LONG READ SEQUENCING DATA.\n",
      "\n",
      "General options:\n",
      "  -h, --help            show the help and exit\n",
      "  -v, --version         Print version and exit.\n",
      "  -t, --threads THREADS\n",
      "                        Set the allowed number of threads to be used by the script\n",
      "  --verbose             Write log messages also to terminal.\n",
      "  --store               Store the extracted data in a pickle file for future plotting.\n",
      "  --raw                 Store the extracted data in tab separated file.\n",
      "  --huge                Input data is one very large file.\n",
      "  -o, --outdir OUTDIR   Specify directory in which output has to be created.\n",
      "  --no_static           Do not make static (png) plots.\n",
      "  -p, --prefix PREFIX   Specify an optional prefix to be used for the output files.\n",
      "  --tsv_stats           Output the stats file as a properly formatted TSV.\n",
      "  --info_in_report      Add NanoPlot run info in the report.\n",
      "\n",
      "Options for filtering or transforming input prior to plotting:\n",
      "  --maxlength N         Hide reads longer than length specified.\n",
      "  --minlength N         Hide reads shorter than length specified.\n",
      "  --drop_outliers       Drop outlier reads with extreme long length.\n",
      "  --downsample N        Reduce dataset to N reads by random sampling.\n",
      "  --loglength           Additionally show logarithmic scaling of lengths in plots.\n",
      "  --percentqual         Use qualities as theoretical percent identities.\n",
      "  --alength             Use aligned read lengths rather than sequenced length (bam mode)\n",
      "  --minqual N           Drop reads with an average quality lower than specified.\n",
      "  --runtime_until N     Only take the N first hours of a run\n",
      "  --readtype {1D,2D,1D2}\n",
      "                        Which read type to extract information about from summary. Options are 1D, 2D,\n",
      "                        1D2\n",
      "  --barcoded            Use if you want to split the summary file by barcode\n",
      "  --no_supplementary    Use if you want to remove supplementary alignments\n",
      "\n",
      "Options for customizing the plots created:\n",
      "  -c, --color COLOR     Specify a valid matplotlib color for the plots\n",
      "  -cm, --colormap COLORMAP\n",
      "                        Specify a valid matplotlib colormap for the heatmap\n",
      "  -f, --format [{png,jpg,jpeg,webp,svg,pdf,eps,json} ...]\n",
      "                        Specify the output format of the plots, which are in addition to the html files\n",
      "  --plots [{kde,hex,dot} ...]\n",
      "                        Specify which bivariate plots have to be made.\n",
      "  --legacy [{kde,dot,hex} ...]\n",
      "                        Specify which bivariate plots have to be made (legacy mode).\n",
      "  --listcolors          List the colors which are available for plotting and exit.\n",
      "  --listcolormaps       List the colors which are available for plotting and exit.\n",
      "  --no-N50              Hide the N50 mark in the read length histogram\n",
      "  --N50                 Show the N50 mark in the read length histogram\n",
      "  --title TITLE         Add a title to all plots, requires quoting if using spaces\n",
      "  --font_scale FONT_SCALE\n",
      "                        Scale the font of the plots by a factor\n",
      "  --dpi DPI             Set the dpi for saving images\n",
      "  --hide_stats          Not adding Pearson R stats in some bivariate plots\n",
      "\n",
      "Input data sources, one of these is required.:\n",
      "  --fastq file [file ...]\n",
      "                        Data is in one or more default fastq file(s).\n",
      "  --fasta file [file ...]\n",
      "                        Data is in one or more fasta file(s).\n",
      "  --fastq_rich file [file ...]\n",
      "                        Data is in one or more fastq file(s) generated by albacore, MinKNOW or guppy\n",
      "                        with additional information concerning channel and time.\n",
      "  --fastq_minimal file [file ...]\n",
      "                        Data is in one or more fastq file(s) generated by albacore, MinKNOW or guppy\n",
      "                        with additional information concerning channel and time. Is extracted swiftly\n",
      "                        without elaborate checks.\n",
      "  --summary file [file ...]\n",
      "                        Data is in one or more summary file(s) generated by albacore or guppy.\n",
      "  --bam file [file ...]\n",
      "                        Data is in one or more sorted bam file(s).\n",
      "  --ubam file [file ...]\n",
      "                        Data is in one or more unmapped bam file(s).\n",
      "  --cram file [file ...]\n",
      "                        Data is in one or more sorted cram file(s).\n",
      "  --pickle pickle       Data is a pickle file stored earlier.\n",
      "  --feather, --arrow file [file ...]\n",
      "                        Data is in one or more feather file(s).\n",
      "\n",
      "EXAMPLES:\n",
      "    NanoPlot --summary sequencing_summary.txt --loglength -o summary-plots-log-transformed\n",
      "    NanoPlot -t 2 --fastq reads1.fastq.gz reads2.fastq.gz --maxlength 40000 --plots hex dot\n",
      "    NanoPlot --color yellow --bam alignment1.bam alignment2.bam alignment3.bam --downsample 10000\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "Nanoplot -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed19e512",
   "metadata": {},
   "source": [
    "Again, that is a LOT. However, we'll do a very simple run - we'll give it a single input file (a fastq file - raw sequencing data). We'll give the program an output folder name, tell it that we want the format of any images generated to be a .png, and tell it that it can use 10 threads.\n",
    "\n",
    "Here, we'll run Nanoplot using a dataset generated at the Institut Pasteur de Lille. This research group sequenced the Zymobiomics microbial community DNA standard using Oxford Nanopore's 16S kit. This kit is designed to amplify the entire 16S rRNA region of bacterial (and archeal) genomes, which on average is 1492 base pairs long.\n",
    "\n",
    "Run the command below - the input is the concatenated fastq file of the sequencing run (meaning that all the fastq files generated during the sequencing experiment were combined into one file), called \"Zymo_16S_SRR25400687.fastq\". The output is a directory which Nanoplot will fill with various files visualizing the sequencing data - we will supply a name for the output file, \"Zymo_16S_SRR25400687_Nanoplot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a4556",
   "metadata": {},
   "outputs": [],
   "source": [
    "NanoPlot --fastq Zymo_16S_SRR25400687.fastq -o Zymo_16S_SRR25400687_Nanoplot -f png -t 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fae8d9",
   "metadata": {},
   "source": [
    "Now let's enter our output folder Zymo_16S_SRR25400687_Nanoplot within the data folder and list the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4dbf1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LengthvsQualityScatterPlot_dot.html\n",
      "LengthvsQualityScatterPlot_dot.png\n",
      "LengthvsQualityScatterPlot_kde.html\n",
      "LengthvsQualityScatterPlot_kde.png\n",
      "NanoPlot-report.html\n",
      "NanoPlot_20230909_2225.log\n",
      "NanoStats.txt\n",
      "Non_weightedHistogramReadlength.html\n",
      "Non_weightedHistogramReadlength.png\n",
      "Non_weightedLogTransformed_HistogramReadlength.html\n",
      "Non_weightedLogTransformed_HistogramReadlength.png\n",
      "WeightedHistogramReadlength.html\n",
      "WeightedHistogramReadlength.png\n",
      "WeightedLogTransformed_HistogramReadlength.html\n",
      "WeightedLogTransformed_HistogramReadlength.png\n",
      "Yield_By_Length.html\n",
      "Yield_By_Length.png\n"
     ]
    }
   ],
   "source": [
    "cd ~/data/Zymo_16S_SRR25400687_Nanoplot\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d094957",
   "metadata": {},
   "source": [
    "Let's take a look at the general stats file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3eaed06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General summary:         \n",
      "Mean read length:                1,365.0\n",
      "Mean read quality:                   9.4\n",
      "Median read length:              1,502.0\n",
      "Median read quality:                10.7\n",
      "Number of reads:               500,000.0\n",
      "Read length N50:                 1,507.0\n",
      "STDEV read length:                 381.3\n",
      "Total bases:               682,499,554.0\n",
      "Number, percentage and megabases of reads above quality cutoffs\n",
      ">Q5:\t496854 (99.4%) 678.1Mb\n",
      ">Q7:\t468390 (93.7%) 644.1Mb\n",
      ">Q10:\t306987 (61.4%) 440.4Mb\n",
      ">Q12:\t129272 (25.9%) 189.0Mb\n",
      ">Q15:\t1516 (0.3%) 2.1Mb\n",
      "Top 5 highest mean basecall quality scores and their read lengths\n",
      "1:\t18.4 (205)\n",
      "2:\t18.3 (163)\n",
      "3:\t18.2 (168)\n",
      "4:\t17.9 (156)\n",
      "5:\t17.8 (149)\n",
      "Top 5 longest reads and their mean basecall quality score\n",
      "1:\t39751 (4.0)\n",
      "2:\t4089 (5.2)\n",
      "3:\t3853 (4.0)\n",
      "4:\t3815 (6.5)\n",
      "5:\t3788 (4.2)\n"
     ]
    }
   ],
   "source": [
    "cat NanoStats.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c2428a",
   "metadata": {},
   "source": [
    "Looks like the average and median read lengths and quality scores are good - they are around or close to ~1500 base pairs, and the Q scores (for R9 flow cells run on a MinION) are quite good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfcb02d-0189-491b-9245-b0c20d57863b",
   "metadata": {},
   "source": [
    "Now, navigate to our results folder in the left-hand file display, and let's look at some of the results we just generated together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
